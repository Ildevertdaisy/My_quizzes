
#1

---

## âŒ Erreur nÂ°2 : Oublier de comparer **le coÃ»t et les bÃ©nÃ©fices**

Avant de commencer Ã  **fabriquer une IA**, il faut toujours se poser une question trÃ¨s importante :

ğŸ‘‰ **Est-ce que Ã§a vaut le coup ?**

Ã‡a veut dire :

* Combien Ã§a va **coÃ»ter** (en argent, en temps, en Ã©nergie),
* Et quâ€™est-ce que Ã§a va vraiment **rapporter** (est-ce que Ã§a aide ? est-ce que Ã§a fait gagner du temps ? est-ce que Ã§a Ã©vite des problÃ¨mes ?).

Mais dans ce projet, lâ€™Ã©quipe a **oubliÃ© de faire ce calcul** avant de se lancerâ€¦
Et câ€™est **une grosse erreur** ğŸ˜¬.

---

### ğŸ“Š Quâ€™est-ce que Ã§a veut dire, â€œcoÃ»tâ€ et â€œbÃ©nÃ©ficeâ€ ?

Quand une IA prend une dÃ©cision, en fait, elle **fait une prÃ©diction**.
Une prÃ©diction, câ€™est **deviner ce qui va se passer** ou **choisir une action** selon les infos quâ€™elle a.

Mais lâ€™IA peut :

* **rÃ©ussir** (bonne prÃ©diction ğŸ‘),
* ou **se tromper** (mauvaise prÃ©diction ğŸ‘).

Et chaque fois :

* Il y a un **coÃ»t** (par exemple : perdre de lâ€™argent, faire une erreur, devoir rÃ©parer),
* Et un **bÃ©nÃ©fice** (par exemple : gagner du temps, Ã©viter un danger, mieux aider un utilisateur).

---

### ğŸ® Exemple avec une appli de jeu

Imaginons une **application de jeu Ã©ducatif** ğŸ®ğŸ§  pour apprendre les maths.

Lâ€™IA peut proposer des exercices **plus faciles ou plus difficiles** selon ton niveau.

* Si elle **se trompe** (elle pense que tu es fort alors que tu ne lâ€™es pas), tu vas Ãªtre **dÃ©couragÃ©**.
* Si elle rÃ©ussit (elle te donne le bon niveau), tu **apprends mieux** et tu **tâ€™amuses**.

Mais pour faire Ã§a, il faut :

* du **temps** pour programmer,
* de lâ€™argent pour payer les dÃ©veloppeurs,
* et peut-Ãªtre acheter des serveurs (les gros ordinateurs qui font tourner lâ€™IA) ğŸ’»ğŸ’¸.

ğŸ‘‰ Donc il faut rÃ©flÃ©chir : **Est-ce que ce que lâ€™IA apporte vaut ce quâ€™on dÃ©pense ?**

---

### ğŸ› ï¸ Ce que lâ€™Ã©quipe a mal fait dans le projet

Dans lâ€™exemple racontÃ© dans le livre :

* Lâ€™Ã©quipe a commencÃ© Ã  **crÃ©er lâ€™IA sans se demander si câ€™Ã©tait rentable**.
* Ils ne savaient pas **combien Ã§a allait coÃ»ter au total**.
* Ils ne savaient pas **si lâ€™IA allait vraiment aider les utilisateurs plus quâ€™un humain**.
* Et surtout, ils ne savaient pas **ce quâ€™ils risquaient si lâ€™IA se trompait**.

Câ€™est comme **fabriquer un robot pour faire des crÃªpes** ğŸ¥â€¦
sans se demander si ce robot coÃ»te **plus cher que dâ€™acheter des crÃªpes toutes faites** ğŸ˜….

---

### ğŸ§  Ce quâ€™on doit toujours faire AVANT de crÃ©er une IA

Avant de commencer :

1. **Comprendre le problÃ¨me** : quâ€™est-ce quâ€™on veut que lâ€™IA fasse ?
2. **Faire un calcul simple** :

   * Combien Ã§a coÃ»te de crÃ©er et faire tourner cette IA ?
   * Que gagne-t-on si elle marche bien ?
   * Que perd-on si elle se trompe ?

Si **les risques sont plus grands que les avantages**,
ou si Ã§a **coÃ»te trop pour un petit bÃ©nÃ©fice**,
ğŸ‘‰ alors **ce nâ€™est pas un bon projet**.

---

### ğŸ“± Autre exemple avec une appli de transport

Imaginons une IA dans une appli de transport qui dit **oÃ¹ garer sa trottinette Ã©lectrique** ğŸ›´.

* Si lâ€™IA dit une place libre alors quâ€™elle est occupÃ©e âŒ : lâ€™utilisateur **perd du temps**.
* Si elle montre bien la vraie place libre âœ… : câ€™est super utile.

Mais crÃ©er cette IA peut coÃ»ter **trÃ¨s cher** si on doit mettre des capteurs partout dans la ville.

Donc avant de la faire, il faut vraiment se demander :
ğŸ‘‰ Est-ce que le **jeu en vaut la chandelle** (câ€™est une expression qui veut dire : est-ce que Ã§a vaut le coÃ»t et lâ€™effort) ?

---

## ğŸ§  RÃ©sumÃ© clair

* Chaque dÃ©cision dâ€™une IA **a un coÃ»t et un bÃ©nÃ©fice**.
* Il faut toujours faire le calcul avant de commencer.
* Sinon, tu risques de **dÃ©penser beaucoupâ€¦ pour pas grand-chose** ğŸ˜•

---

Souhaites-tu que je continue avec la **suite de cette erreur** ou que je passe Ã  la **troisiÃ¨me erreur** ? ğŸ˜Š



#2

---

## ğŸ’¥ Une toute petite erreur qui peut tout faire rater

Lâ€™auteur commence ici par un **conseil important** :
ğŸ‘‰ â€œNe fais pas la mÃªme erreur que nous.â€

Alors quelle erreur ? Câ€™est celle dâ€™avoir **oubliÃ© de rÃ©flÃ©chir aux consÃ©quences dâ€™une seule petite erreur**.

---

### ğŸ Une marmite qui dÃ©borde, câ€™est plus grave que Ã§a en a lâ€™air

Dans leur projet, lâ€™Ã©quipe voulait crÃ©er une intelligence artificielle (IA) pour **Ã©viter que la marmite industrielle dÃ©borde** (comme une grosse casserole de spaghettis dans une usine ğŸ­ğŸ²).

â¡ï¸ **Faire en sorte quâ€™elle ne dÃ©borde pas**, câ€™est simple : **il suffit de baisser le feu** ğŸ”¥.
Mais si tu **rates juste une seule fois**, Ã§a peut coÃ»ter **trÃ¨s trÃ¨s cher** ğŸ’¸ğŸ’¥.

---

### ğŸ’¸ Une seule erreur coÃ»te plus que le salaire dâ€™un humain sur un an !

Imagine que lâ€™IA **laisse la marmite dÃ©border une seule fois**.
ğŸ‘‰ Rien que ce dÃ©bordement **coÃ»te plus cher** que **payer un humain expert pendant toute une annÃ©e entiÃ¨re** ğŸ˜±.

Donc, si tu veux **remplacer ce technicien humain par une IA**, cette IA doit Ãªtre **quasiment parfaite**.
Elle ne peut **presque jamais** se tromper.

---

### âš–ï¸ Le rapport 1000 contre 1 (câ€™est Ã©norme !)

Lâ€™auteur donne ici un exemple avec des chiffres :

> Si lâ€™IA fait 1 000 bonnes prÃ©dictions (â€œtout va bien, pas de dÃ©bordementâ€),
> mais quâ€™elle rate **juste une seule fois** et laisse vraiment dÃ©border la marmiteâ€¦
> ğŸ‘‰ Alors **tout ce bon travail est annulÃ©**. Le dÃ©bordement coÃ»te tellement cher que Ã§a **efface tous les bÃ©nÃ©fices**.

ğŸ“Š On appelle Ã§a un **rapport de 1000 contre 1** :
**1 seule erreur** peut annuler **1000 bonnes actions**.

---

### ğŸ® Exemple avec une appli de sÃ©curitÃ© dans un jeu vidÃ©o

Imaginons une IA dans un jeu vidÃ©o en ligne ğŸ® qui surveille les comptes pour Ã©viter les tricheurs.

* Si elle repÃ¨re **1000 joueurs honnÃªtes**, câ€™est bien.
* Mais si **elle rate un seul tricheur** qui casse le jeu pour tous les autres joueursâ€¦ ğŸ˜¤
  Alors tous les efforts sont gÃ¢chÃ©s.

Dans ce cas, **mÃªme une seule erreur peut ruiner lâ€™expÃ©rience de tout le monde**.

---

### ğŸ§  Ce quâ€™on doit retenir

* Parfois, **une erreur minuscule peut avoir un Ã©norme impact**.
* Il faut rÃ©flÃ©chir :
  ğŸ‘‰ â€œQuâ€™est-ce qui se passe si lâ€™IA **se trompe juste une fois** ?â€
* Si la rÃ©ponse est : â€œOn perd **tout le bÃ©nÃ©fice** quâ€™on a gagnÃ© avec les bonnes prÃ©dictionsâ€â€¦
  alors ce nâ€™est **pas un bon projet** dâ€™IA, **ou alors il faut que lâ€™IA soit quasiment parfaite**.

Et dans la vraie vie, aucune IA nâ€™est **parfaite Ã  100 %**. MÃªme les meilleures **peuvent se tromper un jour**.

---

## ğŸ¯ RÃ©sumÃ© simple

* Le but de lâ€™IA dans ce projet Ã©tait dâ€™**Ã©viter un gros dÃ©bordement**.
* Mais **une seule erreur** pouvait **coÃ»ter plus cher que tout ce que lâ€™IA avait bien fait pendant un an**.
* RÃ©sultat ? ğŸ’¡ Le risque est **trop grand**, donc **Ã§a ne vaut pas le coup** de remplacer lâ€™humain ici.

---



#3

---

## ğŸ—ï¸ Trop cher, pas assez utile = Personne nâ€™en veut

Dans cette derniÃ¨re partie de lâ€™erreur nÂ°2, lâ€™auteur explique **pourquoi câ€™Ã©tait si difficile de convaincre les clients dâ€™utiliser leur IA** Ã  la place du technicien humain.

ğŸ‘‰ Et la rÃ©ponse est trÃ¨s simple : **Ã§a ne valait pas le coup**.

---

### âš–ï¸ Un Ã©quilibre complÃ¨tement dÃ©sÃ©quilibrÃ©

Lâ€™auteur parle dâ€™un **dÃ©sÃ©quilibre entre le coÃ»t et le bÃ©nÃ©fice** (câ€™est ce quâ€™il appelle un *â€œskewed cost/benefit impactâ€*).

ğŸ§  Ce que Ã§a veut dire :

* Lâ€™**IA coÃ»tait beaucoup** (pour lâ€™installer, pour lâ€™utiliser, pour la maintenir),
* Mais elle nâ€™avait **pas encore fait ses preuves** (elle nâ€™avait jamais montrÃ© quâ€™elle savait bien faire ce travail),
* Et **elle nâ€™Ã©tait pas entraÃ®nÃ©e** sur les vraies machines de lâ€™usine (donc elle ne comprenait pas encore bien comment tout marchait ğŸ˜¬).

En face de Ã§a, il y avait :

* Un **humain** dÃ©jÃ  lÃ ,
* Qui connaissait trÃ¨s bien la marmite,
* Qui **faisait bien son travail tous les jours**,
* Et qui **coÃ»tait moins cher** ğŸ’°.

Alors tu imagines bien que les clients ont dit :
ğŸ‘‰ â€œPourquoi on paierait plus cher pour un robot qui ne sait mÃªme pas encore comment Ã§a marche ?â€ ğŸ™…â€â™‚ï¸

---

### ğŸ® Exemple dans un jeu vidÃ©o en ligne

Imaginons un jeu oÃ¹ tu veux remplacer les **modÃ©rateurs humains** (les personnes qui surveillent les discussions entre joueurs pour Ã©viter les insultes ou la triche) par une **IA trÃ¨s chÃ¨re**.

Mais :

* Lâ€™IA ne reconnaÃ®t pas bien lâ€™humour, les fautes de frappe ou les emojis,
* Elle fait des erreurs (elle punit parfois un joueur gentil, ou laisse passer un vrai tricheur),
* Et elle coÃ»te **plus cher que les modÃ©rateurs humains** qui font Ã§a **trÃ¨s bien depuis des annÃ©es**.

RÃ©sultat ?
ğŸ‘‰ Aucun patron de jeu vidÃ©o nâ€™aurait envie dâ€™acheter cette IA tant quâ€™elle **nâ€™est pas meilleure** que ce qui existe dÃ©jÃ .

---

### ğŸ“± Autre exemple avec une application de livraison

Prenons une application qui gÃ¨re les tournÃ©es de livreurs de repas ğŸ”.

Tu proposes une IA qui dit :

* â€œJe vais remplacer le chef de planning humain par un super algorithme.â€

Mais si :

* Lâ€™algorithme est **cher Ã  faire tourner**,
* Il ne connaÃ®t pas bien les **quartiers compliquÃ©s**,
* Et il **fait des erreurs de calculs** quand il pleut ou quand il y a des travauxâ€¦

Alors le responsable va te dire :
ğŸ‘‰ â€œNon merci, jâ€™ai dÃ©jÃ  quelquâ€™un qui fait Ã§a trÃ¨s bien pour moins cher.â€ ğŸ˜

---

## ğŸ§  RÃ©sumÃ© simple Ã  retenir

* Quand ton projet dâ€™IA **coÃ»te beaucoup**, mais **nâ€™aide pas beaucoup**, il est **trÃ¨s difficile Ã  vendre**.
* Si les gens ont **dÃ©jÃ  une solution qui marche bien**, ils ne voudront pas la changer pour un truc :

  * plus cher ğŸ’¸,
  * moins fiable ğŸ˜•,
  * et pas encore prÃªt ğŸ£.

ğŸ‘‰ Donc avant de proposer une IA, il faut **vraiment sâ€™assurer quâ€™elle apporte plus dâ€™avantages que ce quâ€™on a dÃ©jÃ **.

---



#4

---

## ğŸ’¥ Une IA qui peut causer une grosse erreurâ€¦ et personne ne veut en payer les consÃ©quences

Alors lÃ , on arrive Ã  un dernier gros problÃ¨me du projet. Et câ€™est **encore plus grave**.

ğŸ‘‰ Lâ€™entreprise qui avait fabriquÃ© cette intelligence artificielle (IA) a dit :

> â€œSi notre IA fait une erreur graveâ€¦ **ce nâ€™est pas notre faute**. On ne paiera **rien**.â€ ğŸ˜

Câ€™est ce quâ€™on appelle ici un **dÃ©sincitatif**.
ğŸ“Œ *DÃ©sincitatif*, Ã§a veut dire : une **raison de plus de ne pas acheter le produit**.
Câ€™est un peu comme si tu disais :

> â€œSi tu achÃ¨tes mon vÃ©lo, je ne te rembourse pas si les freins lÃ¢chent.â€ ğŸš²ğŸ˜¬

Eh bien lÃ , câ€™Ã©tait pareil avec lâ€™IA :

* Si lâ€™IA **devinait mal**,
* Et que Ã§a faisait **dÃ©border la marmite gÃ©ante** dans lâ€™usine ğŸğŸ”¥,
* Et que Ã§a causait **des dÃ©gÃ¢ts trÃ¨s chers** Ã  rÃ©parerâ€¦

ğŸ‘‰ Alors **le client devait payer tout seul** les dÃ©gÃ¢ts, **mÃªme si câ€™Ã©tait la faute de lâ€™IA** !

---

### ğŸ¤¯ RÃ©sultat ? Plus personne ne veut du projet

Tu imagines bien que **personne ne voulait prendre ce risque**.

Câ€™est comme vendre une **application de sÃ©curitÃ©** pour une maison ğŸ ğŸ”’ et dire :

> â€œSi lâ€™alarme ne sonne pas quand un voleur entre, ce nâ€™est pas notre problÃ¨me.â€

Dans ce cas-lÃ , **personne ne voudra lâ€™acheter**, mÃªme si lâ€™appli a lâ€™air super bien.

---

### ğŸ® Exemple dans une appli de jeux

Imaginons une IA qui dÃ©tecte les tricheurs dans un jeu en ligne ğŸ®.

Mais si elle **bannit un joueur honnÃªte** Ã  cause dâ€™une erreur, et que les crÃ©ateurs du jeu disent :

> â€œCe nâ€™est pas notre faute, tant pis pour vous,â€
> alors les joueurs vont se fÃ¢cher ğŸ˜  et **quitter le jeu**.

Tu ne peux pas vendre un outil qui peut faire de grosses erreurs **et refuser dâ€™en assumer la responsabilitÃ©**.

---

### ğŸ§  Ce quâ€™on apprend ici

1. ğŸ’¡ Si tu proposes une IA, tu dois aussi penser Ã  **ce qui se passe quand elle se trompe**.
2. Si lâ€™IA peut causer **des pertes Ã©normes**, il faut **protÃ©ger le client**.
3. Dire **"on ne paiera rien mÃªme si câ€™est de notre faute"**, câ€™est comme **offrir un produit sans garantie** : Ã§a **fait fuir tout le monde**.

---

## ğŸ›‘ RÃ©sumÃ© simple

* Le projet Ã©tait dÃ©jÃ  mal parti (trop cher, pas assez utile, pas fiable),
* Mais lÃ , câ€™est le **coup final** :
  ğŸ‘‰ Le fabricant ne voulait **mÃªme pas prendre la responsabilitÃ©** des dÃ©gÃ¢ts si leur IA faisait une grosse bÃªtise.

Et donc, comme dit dans le texte, le projet est devenu un **â€œnon-starterâ€** â€”
ğŸ“Œ Ã§a veut dire que **personne nâ€™a voulu commencer**.
Le projet Ã©tait **mort avant mÃªme de dÃ©marrer**.

---




#5


---

## âš ï¸ Petit rappel trÃ¨s important : Attention aux consÃ©quences des erreurs dâ€™IA

Dans cette **note** (câ€™est-Ã -dire une sorte dâ€™avertissement ou de conseil rapide), lâ€™auteur te dit de **faire trÃ¨s attention Ã  un point prÃ©cis** quand tu crÃ©es ou utilises une intelligence artificielle (IA).

ğŸ’¡ Il te dit :

> â€œSi une erreur de lâ€™IA peut causer **beaucoup plus de mal** quâ€™une bonne prÃ©diction peut apporter de bien, alors **laisse tomber** ce projet.â€

Et il ajoute mÃªme :

> â€œSi une erreur peut Ãªtre **catastrophique** (vraiment trÃ¨s grave), alors **pars en courant** !â€ ğŸƒğŸ’¨

---

### ğŸ§  Ce que Ã§a veut dire simplement

Lâ€™IA, on le rappelle, câ€™est un systÃ¨me qui **prend des dÃ©cisions ou fait des prÃ©dictions** en se basant sur des donnÃ©es (comme des exemples quâ€™on lui a montrÃ©s).

Mais elle peut se **tromper** parfois.

Et lÃ , on te dit :

* Si elle se trompe, **est-ce que câ€™est grave ?**
* Est-ce que cette erreur **va faire perdre beaucoup dâ€™argent, casser quelque chose, ou mettre des gens en danger** ?

Si **oui**, alors il vaut mieux **ne pas utiliser lâ€™IA dans ce cas prÃ©cis**, mÃªme si elle peut Ãªtre utile de temps en temps.

---

### ğŸ® Exemple avec une IA dans un jeu de construction

Imagine une IA dans un jeu oÃ¹ tu construis une ville ğŸ™ï¸.
Elle tâ€™aide Ã  placer les bÃ¢timents automatiquement.

Si elle fait une erreur et met une maison Ã  la place dâ€™un parc, ce nâ€™est **pas grave**. Tu peux corriger facilement.
âœ… *Dans ce cas, câ€™est OK dâ€™utiliser lâ€™IA.*

Mais maintenant imagine une IA qui gÃ¨re les freins dans une voiture autonome ğŸš— :

* Si elle rÃ©ussit : super, elle freine bien.
* Si elle se trompe : **accident** ! ğŸ˜±

LÃ , **une seule erreur peut coÃ»ter une vie**, ou beaucoup dâ€™argent.

âŒ *Donc dans ce genre de cas, il faut vraiment rÃ©flÃ©chir avant dâ€™utiliser lâ€™IA, ou sâ€™assurer quâ€™elle est trÃ¨s trÃ¨s fiable.*

---

### ğŸ“¦ Autre exemple avec une appli de livraison

Imaginons une IA qui dÃ©cide toute seule **oÃ¹ envoyer les colis** ğŸ“¦.

* Si elle se trompe une fois et quâ€™un client reÃ§oit le mauvais colisâ€¦
  ğŸ‘‰ Ã‡a coÃ»te du temps, un retour, un client pas contentâ€¦
  Mais ce nâ€™est **pas catastrophique**.

Mais si câ€™est une IA qui dÃ©cide **quand et comment envoyer des produits dangereux** (comme du gaz ou des produits chimiques), lÃ  :

* **Une erreur peut provoquer un accident industriel**.

Dans ce cas, **mieux vaut ne pas utiliser lâ€™IA du tout** si on nâ€™est pas sÃ»r Ã  100 % de sa prÃ©cision.

---

## ğŸ›‘ RÃ©sumÃ© super simple

* Si une **erreur dâ€™IA peut causer plus de mal que le bien quâ€™elle apporte**, **nâ€™utilise pas cette IA**.
* Si une erreur peut Ãªtre **trÃ¨s grave** (danger, Ã©norme perte, blessure, mort), alors **ne commence mÃªme pas**.
  ğŸ‘‰ Câ€™est trop risquÃ©.

---


#6


---

## ğŸ“˜ Une mÃ©thode expliquÃ©e plus loin pour mieux rÃ©flÃ©chir avant de lancer un projet dâ€™IA

Ici, lâ€™auteur te dit :
ğŸ‘‰ â€œSi tu veux apprendre Ã  **bien rÃ©flÃ©chir avant de lancer une IA**, je tâ€™expliquerai **en dÃ©tail comment faire** dans le **chapitre 5** du livre.â€

Ce chapitre sâ€™appelle :
ğŸ¯ *â€œLa matrice de valeur â€” Lâ€™exactitude de lâ€™IA, câ€™est du bluff. Voici ce que le design UX doit vraiment faire.â€*

Ouh lÃ  ! ğŸ˜® Il y a beaucoup de mots ici. Pas de panique, on va tout **dÃ©couper et simplifier**.

---

### ğŸ§® Câ€™est quoi une "analyse coÃ»t/bÃ©nÃ©fice" ?

Une **analyse coÃ»t/bÃ©nÃ©fice**, câ€™est un peu comme une balance âš–ï¸ :

* Dâ€™un cÃ´tÃ©, tu mets **tout ce que tu vas devoir payer ou risquer** (le coÃ»t),
* Et de lâ€™autre cÃ´tÃ©, tu mets **tout ce que tu peux gagner ou amÃ©liorer** (le bÃ©nÃ©fice).

ğŸ‘‰ Si les bÃ©nÃ©fices sont **plus grands que les risques**, tu peux essayer.
ğŸ‘‰ Mais si **une seule erreur peut tout gÃ¢cher**, il faut peut-Ãªtre abandonner lâ€™idÃ©e.

Câ€™est **exactement ce quâ€™on a vu dans lâ€™erreur nÂ°2**.

---

### ğŸ“Š Et câ€™est quoi une "valeur matrix" (ou matrice de valeur) ?

Une *matrice de valeur*, câ€™est **un tableau tout simple** qui tâ€™aide Ã  voir **ce que chaque action de lâ€™IA peut vraiment apporter ou faire perdre**, selon quâ€™elle rÃ©ussit ou quâ€™elle se trompe.

Câ€™est comme faire **un tableau de points** dans un jeu ğŸ® :

* Si lâ€™IA fait une bonne action â• tu gagnes des points,
* Si elle fait une erreur â– tu perds beaucoup (parfois **Ã©normÃ©ment**).

ğŸ‘‰ Ce tableau tâ€™aide Ã  **voir tout Ã§a clairement** avant de construire quoi que ce soit.

---

### ğŸ˜¬ Et pourquoi il dit que â€œlâ€™exactitude de lâ€™IA, câ€™est du bluffâ€ ?

Parce que beaucoup de gens pensent que **si une IA a un bon score de rÃ©ussite (comme 95 %), alors câ€™est suffisant**.

Mais ce que lâ€™auteur veut dire, câ€™est :

> MÃªme si ton IA se trompe **juste 5 fois sur 100**,
> **si ces 5 erreurs coÃ»tent une fortune**, Ã§a **ne vaut pas le coup** du tout.

ğŸ“Œ Câ€™est comme dire :

> â€œJe fais rarement des fautes dans mon appli GPS ğŸš—, mais une fois jâ€™ai envoyÃ© un camion dans un lac.â€

Tu comprends ? ğŸ˜… MÃªme une **petite erreur** peut Ãªtre **trÃ¨s grave**, alors **le score de prÃ©cision nâ€™est pas suffisant** pour dire que lâ€™IA est bonne.

---

### ğŸ® Exemple avec une appli de quiz Ã©ducatif

Tu as une appli de quiz pour apprendre lâ€™histoire ğŸ›ï¸.

* Si lâ€™IA te donne 90 bonnes questions sur 100, câ€™est trÃ¨s bien.
* Les 10 erreurs sont **pas trÃ¨s graves** (juste des questions mal formulÃ©es).

Mais si tu as une **appli mÃ©dicale** ğŸ¥ qui aide Ã  repÃ©rer des maladiesâ€¦
et quâ€™elle **rate 5 personnes malades sur 100**,
ğŸ‘‰ lÃ , **les consÃ©quences sont Ã©normes** !

---

## ğŸ§  Ce quâ€™on apprend ici

* Il ne faut **pas juste regarder le score de rÃ©ussite** dâ€™une IA.
* Il faut **vraiment comprendre** :

  * Quâ€™est-ce que chaque action de lâ€™IA apporte ?
  * Et quâ€™est-ce que chaque erreur coÃ»te ?
* Le chapitre 5 expliquera **pas Ã  pas** comment crÃ©er ce tableau de rÃ©flexion (appelÃ© *matrice de valeur*) pour **prendre les bonnes dÃ©cisions** avant de lancer un projet.

---
